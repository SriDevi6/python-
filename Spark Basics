All the big data products are licensed to Apache Software Foundations( ASF). 
Apache hadoop , Apache Spark, Apache hive , APACHE pig, Apache Sqoop are product of ASF.
Most of the ASF Products are java based. Most of ASF Products are mostly written in scala. So it is preferred to learn spark using scala.

SPARK- Big data processing Framework
Hadoop MP and Spark
  MP:
  
  MP uses Disk to perform i/p and o/p operations.
  Assume we have Data of 10GB which is stored in HDFS (ie disk),
  we have to write a map reduce job, the op of this map reduce job is written back to hdfs,
  if we have anothe mr job which would consume this data , 
  then we would have to again read the data from this hdfs and process it write the data to hdfs
  so it is going to be slow.
  Everytime you want to run MR Program , the data has to be loaded from HDFS(Disk) to your memory and get it processed and then again the output is thrown back to the disk that is HDFS. This made MR slow
SP:
  The data will be initially residing in HDFS. When we write a spark job, the data will be loaded into memory(RAM) , 
  data will be processed in memory and the intermediate results is also written back to the memory.
  As the data is residing in memory makes Spark's processing faster compared to MP. so spark is called Distributed IN- MEMORY Framework.
  
  When to use SP or MR?
 Speed:
   If data has to be processed really fast, then solutions are written using Spark.
   If data can be processed in some delay (with low latency),then solutions are written using MR.
  Cost:
   MR uses disk , which is less in cost compared to RAM used by Spark
   eg 2TB-4000INR, 12BG-4000INR
  Based on the priority, Companies adopt either MR or Spark or sometimes both.
    Data has to be processed really quick, then invest lot of money in spark clusters 
    or go with else Map Reduce.
    If you dont require results immediately, Map reduce can be used instead of Spark.
    
 Writing MR program means not writting MR Code, instead we can use hive which INTERNALLY uses MR
 Framework for different big data problems
 Limitation OF mr?
  refer img.
 How Spark is fast?
   in memory processing combined with its DAG based data processing engine makes Spark very efficient.
 Spark replacement of Hadoop?
   Spark is just a processing engine.
   Spark is not meant to process the data not store the data.
 Some companies use both MR Cluster and Saprk Cluster.
   refer img.

 
   
 
 MR- Batch
 Spark- Batch,Real time (Processing the data asap).
 Use case:
 Financial risk estimation:
 Some people will default the loan ,
 so big data will help in indentifying the risk in financial institution.
 
   
 
 
    
    
    
    
  
  
  
